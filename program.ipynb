{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given any type of comments, This program can detect the profanity of the comment along with different metrics.A good and long list containing profanity words is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#cleaning comment from links,tags and numbers\n",
    "def clean_text(comment):\n",
    "    return ''.join(re.sub(r\"(@[A-Za-z0-9]+)|(http\\S+)|(\\$[A-Za-z0-9]+)|([0-9]+)\",\"\",comment))\n",
    "def remove_special_chars(comment):# unrolls hastags and also removes symbols\n",
    "    for remove in map(lambda r: re.compile(re.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "        comment.replace(remove, \"\", inplace=True)\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Comment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello bitch</td>\n",
       "      <td>Hello bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bye bye love</td>\n",
       "      <td>bye bye love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#BITCH</td>\n",
       "      <td>BITCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User       Comment    clean_text\n",
       "0     1   Hello bitch   Hello bitch\n",
       "1     2  bye bye love  bye bye love\n",
       "2     3        #BITCH         BITCH"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"]=df['Comment'].apply(lambda row: clean_text(row))\n",
    "remove_special_chars(df.clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Comment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>filteredsent</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello bitch</td>\n",
       "      <td>Hello bitch</td>\n",
       "      <td>[hello, bitch]</td>\n",
       "      <td>[hello, bitch]</td>\n",
       "      <td>[hello, bitch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bye bye love</td>\n",
       "      <td>bye bye love</td>\n",
       "      <td>[bye, bye, love]</td>\n",
       "      <td>[bye, bye, love]</td>\n",
       "      <td>[bye, bye, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#BITCH</td>\n",
       "      <td>BITCH</td>\n",
       "      <td>[bitch]</td>\n",
       "      <td>[bitch]</td>\n",
       "      <td>[bitch]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User       Comment    clean_text    tokenized_text      filteredsent  \\\n",
       "0     1   Hello bitch   Hello bitch    [hello, bitch]    [hello, bitch]   \n",
       "1     2  bye bye love  bye bye love  [bye, bye, love]  [bye, bye, love]   \n",
       "2     3        #BITCH         BITCH           [bitch]           [bitch]   \n",
       "\n",
       "         Lemmatized  \n",
       "0    [hello, bitch]  \n",
       "1  [bye, bye, love]  \n",
       "2           [bitch]  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def filter_text(text):\n",
    "    filtered=[]\n",
    "    for w in text:\n",
    "        if w.lower() not in stopwords.words('english'):\n",
    "            filtered.append(w)\n",
    "    return filtered\n",
    "def lower(array):\n",
    "    arr=[]\n",
    "    for text in array:\n",
    "        arr.append(text.lower())\n",
    "    return arr\n",
    "def get_pos(word):\n",
    "    tag=nltk.pos_tag([word])[0][1][0]\n",
    "    if tag =='J':\n",
    "        return wordnet.ADJ\n",
    "    elif tag =='V':\n",
    "        return wordnet.VERB\n",
    "    elif tag =='N':\n",
    "        return wordnet.NOUN\n",
    "    elif tag =='R':\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "ps=LancasterStemmer()\n",
    "\n",
    "\n",
    "df['tokenized_text'] = df.apply(lambda row :lower(word_tokenize(row['clean_text'])), axis=1)\n",
    "\n",
    "\n",
    "df['filteredsent'] = df['tokenized_text'].apply(lambda row : filter_text(row))\n",
    "\n",
    "# We can either use stemmed version or lemmatized version for further analysis.\n",
    "#here we used lemmatized\n",
    "df['Lemmatized']=df.apply(lambda row :[lem.lemmatize(i,pos=get_pos(i)) for i in row['filteredsent']],axis=1)\n",
    "# df['stemwords'] = df.apply(lambda row : [ps.stem(i) for i in row['filteredsent']],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bitch', 'fucking', 'asshole']\n"
     ]
    }
   ],
   "source": [
    "profanity_words=[\"bitch\",\"fucking\",\"asshole\"]\n",
    "profanity_words=lower(profanity_words)\n",
    "print(profanity_words)\n",
    "#use profanity_words_lem or profanity_words_stem depending on what was selected in preprocessing step\n",
    "profanity_words_lem =[lem.lemmatize(i,pos=get_pos(i)) for i in profanity_words]\n",
    "# profanity_words_stem =[ps.stem(i) for i in profanity_words ]\n",
    "def IndexofProfanity(df,percent=False):\n",
    "    feature=0\n",
    "    for i in profanity_words:\n",
    "        if i in df:\n",
    "            feature+=1\n",
    "    if percent==True:\n",
    "        return feature/len(df)\n",
    "    else:\n",
    "        return feature\n",
    "def Range(num):\n",
    "    if num > 0.8:\n",
    "        return \"extreme\"\n",
    "    elif num >0.4:\n",
    "        return \"High\"\n",
    "    elif num>0.1:\n",
    "        return \"Low\"\n",
    "    elif num == 0:\n",
    "        return \"Clean\"\n",
    "    else:\n",
    "        return \"very Low\"\n",
    "       \n",
    "df['Profanity_words']=df['Lemmatized'].apply(lambda row: IndexofProfanity(row))\n",
    "df['Profanity_percentage']=df['Lemmatized'].apply(lambda row: IndexofProfanity(row,percent=True))\n",
    "df['Profanity_level']=df['Lemmatized'].apply(lambda row: Range(IndexofProfanity(row,percent=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Profanity_words</th>\n",
       "      <th>Profanity_percentage</th>\n",
       "      <th>Profanity_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bye bye love</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#BITCH</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>extreme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User       Comment  Profanity_words  Profanity_percentage Profanity_level\n",
       "0     1   Hello bitch                1                   0.5         High\n",
       "1     2  bye bye love                0                   0.0           Clean\n",
       "2     3        #BITCH                1                   1.0         extreme"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(columns=[\"clean_text\",\"tokenized_text\",\"filteredsent\",\"Lemmatized\"])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
